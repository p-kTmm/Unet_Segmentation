{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NEED GGCOLAB PRO --> MORE THAN 15GB GPU RAM**"
      ],
      "metadata": {
        "id": "l8AeHSuN9PSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuH21Olqq8uq",
        "outputId": "5837d137-53b7-43da-c924-f37f93ed631b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Unet_Segmentation'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "Receiving objects: 100% (8/8), done.\n",
            "remote: Total 8 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/p-kTmm/Unet_Segmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Unet_Segmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcBsL3fxsZWr",
        "outputId": "d4d2b5d9-bd97-4a5a-924c-ff56025d7908"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Unet_Segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "from unet import UNet\n",
        "from carvana_dataset import CarvanaDataset"
      ],
      "metadata": {
        "id": "N0i1LbusrUYu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "FUWBX9BTuu6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the base directory\n",
        "base_dir = '/content/Unet_Segmentation'\n",
        "\n",
        "# Paths for the 'data' and 'models' directories\n",
        "data_dir = os.path.join(base_dir, 'data')\n",
        "models_dir = os.path.join(base_dir, 'models')\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "os.makedirs(models_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "4TrtJjblrqyC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use datasets on kaggle: https://www.kaggle.com/c/carvana-image-masking-challenge/data"
      ],
      "metadata": {
        "id": "HYRy1HL5AiDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, you need to upload the **kaggle.json** file in **/content/Unet_Segmentation** which is required for accessing Kaggle's API. You can download it on kaggle API account"
      ],
      "metadata": {
        "id": "dMjLQxrK1kJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c carvana-image-masking-challenge"
      ],
      "metadata": {
        "id": "y7v-J0lDu3Cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a27c03-12ac-4542-edd1-9bd53f81b8d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "Downloading carvana-image-masking-challenge.zip to /content/Unet_Segmentation\n",
            "100% 24.4G/24.4G [04:28<00:00, 91.4MB/s]\n",
            "100% 24.4G/24.4G [04:28<00:00, 97.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/Unet_Segmentation/carvana-image-masking-challenge.zip -d /content/Unet_Segmentation/data"
      ],
      "metadata": {
        "id": "8s0s9KHp2r1C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/Unet_Segmentation/data/train.zip -d /content/Unet_Segmentation/data\n",
        "!unzip -q /content/Unet_Segmentation/data/train_masks.zip -d /content/Unet_Segmentation/data"
      ],
      "metadata": {
        "id": "AQGQo8xgvdQA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "tydpmVPvuzdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 3e-4\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 2\n",
        "DATA_PATH = \"/content/Unet_Segmentation/data\"\n",
        "MODEL_SAVE_PATH = \"/content/Unet_Segmentation/models/unet.pth\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "\n",
        "train_dataset = CarvanaDataset(DATA_PATH)\n",
        "\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "train_dataset, val_dataset = random_split(train_dataset, [0.8, 0.2], generator=generator)\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=True)"
      ],
      "metadata": {
        "id": "1YpN5xzyrgUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247fdfbc-bc73-47b2-c1eb-d91be4ec90d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(in_channels=3, num_classes=1).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    model.train()\n",
        "    train_running_loss = 0\n",
        "    for idx, img_mask in enumerate(tqdm(train_dataloader)):\n",
        "        img = img_mask[0].float().to(device)\n",
        "        mask = img_mask[1].float().to(device)\n",
        "\n",
        "        y_pred = model(img)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(y_pred, mask)\n",
        "        train_running_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss = train_running_loss / (idx + 1)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for idx, img_mask in enumerate(tqdm(val_dataloader)):\n",
        "            img = img_mask[0].float().to(device)\n",
        "            mask = img_mask[1].float().to(device)\n",
        "\n",
        "            y_pred = model(img)\n",
        "            loss = criterion(y_pred, mask)\n",
        "\n",
        "            val_running_loss += loss.item()\n",
        "\n",
        "        val_loss = val_running_loss / (idx + 1)\n",
        "\n",
        "    print(\"-\"*30)\n",
        "    print(f\"Train Loss EPOCH {epoch+1}: {train_loss:.4f}\")\n",
        "    print(f\"Valid Loss EPOCH {epoch+1}: {val_loss:.4f}\")\n",
        "    print(\"-\"*30)\n",
        "\n",
        "torch.save(model.state_dict(), MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "XwmgXcGC4WRj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "S6Hr3ENb-b_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SINGLE_IMG_PATH = \"/content/Unet_Segmentation/data/29bb3ece3180_11.jpg\"\n",
        "DATA_PATH = \"/content/Unet_Segmentation/data\"\n",
        "MODEL_PATH = \"./models/unet.pth\"  #change this if u want to use your model"
      ],
      "metadata": {
        "id": "kmuBBMQS-wOr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "from carvana_dataset import CarvanaDataset\n",
        "from unet import UNet\n",
        "\n",
        "def pred_show_image_grid(data_path, model_pth, device):\n",
        "    model = UNet(in_channels=3, num_classes=1).to(device)\n",
        "    model.load_state_dict(torch.load(model_pth, map_location=torch.device(device)))\n",
        "    image_dataset = CarvanaDataset(data_path, test=True)\n",
        "    images = []\n",
        "    orig_masks = []\n",
        "    pred_masks = []\n",
        "\n",
        "    for img, orig_mask in image_dataset:\n",
        "        img = img.float().to(device)\n",
        "        img = img.unsqueeze(0)\n",
        "\n",
        "        pred_mask = model(img)\n",
        "\n",
        "        img = img.squeeze(0).cpu().detach()\n",
        "        img = img.permute(1, 2, 0)\n",
        "\n",
        "        pred_mask = pred_mask.squeeze(0).cpu().detach()\n",
        "        pred_mask = pred_mask.permute(1, 2, 0)\n",
        "        pred_mask[pred_mask < 0]=0\n",
        "        pred_mask[pred_mask > 0]=1\n",
        "\n",
        "        orig_mask = orig_mask.cpu().detach()\n",
        "        orig_mask = orig_mask.permute(1, 2, 0)\n",
        "\n",
        "        images.append(img)\n",
        "        orig_masks.append(orig_mask)\n",
        "        pred_masks.append(pred_mask)\n",
        "\n",
        "    images.extend(orig_masks)\n",
        "    images.extend(pred_masks)\n",
        "    fig = plt.figure()\n",
        "    for i in range(1, 3*len(image_dataset)+1):\n",
        "       fig.add_subplot(3, len(image_dataset), i)\n",
        "       plt.imshow(images[i-1], cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def single_image_inference(image_pth, model_pth, device):\n",
        "    model = UNet(in_channels=3, num_classes=1).to(device)\n",
        "    model.load_state_dict(torch.load(model_pth, map_location=torch.device(device)))\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((512, 512)),\n",
        "        transforms.ToTensor()])\n",
        "\n",
        "    img = transform(Image.open(image_pth)).float().to(device)\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    pred_mask = model(img)\n",
        "\n",
        "    img = img.squeeze(0).cpu().detach()\n",
        "    img = img.permute(1, 2, 0)\n",
        "\n",
        "    pred_mask = pred_mask.squeeze(0).cpu().detach()\n",
        "    pred_mask = pred_mask.permute(1, 2, 0)\n",
        "    pred_mask[pred_mask < 0]=0\n",
        "    pred_mask[pred_mask > 0]=1\n",
        "\n",
        "    fig = plt.figure()\n",
        "    for i in range(1, 3):\n",
        "        fig.add_subplot(1, 2, i)\n",
        "        if i == 1:\n",
        "            plt.imshow(img, cmap=\"gray\")\n",
        "        else:\n",
        "            plt.imshow(pred_mask, cmap=\"gray\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "0iVjIbac80gX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to run prediction on multiple images, you must use pred_show_image_grid() function by giving your data path, model path and device as arguments.\n",
        "Make 2 folder and put your images in those:\n",
        "- /content/Unet_Segmentation/data/manual_test\n",
        "- /content/Unet_Segmentation/data/manual_test_masks"
      ],
      "metadata": {
        "id": "eFrKfWQz_uJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# pred_show_image_grid(DATA_PATH, MODEL_PATH, device)\n",
        "single_image_inference(SINGLE_IMG_PATH, MODEL_PATH, device)"
      ],
      "metadata": {
        "id": "yl7zTyc8-5Ba"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}